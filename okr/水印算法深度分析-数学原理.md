# 水印嵌入与提取算法深度分析：算法逻辑与数学原理

> **分析视角**: 顶级架构师 + 数学理论深度剖析  
> **分析目标**: 深入理解水印算法的数学基础与实现细节

---

## 目录

1. [MoELSHWatermark 算法深度分析](#moelshwatermark)
2. [KGW 算法深度分析](#kgw)
3. [Unigram 算法深度分析](#unigram)
4. [EPW 算法深度分析](#epw)
5. [算法对比与数学原理总结](#comparison)

---

## 一、MoELSHWatermark 算法深度分析 {#moelshwatermark}

### 1.1 算法概述

**MoELSHWatermark** 是一种基于 **MoE (Mixture of Experts) 路由权重**和 **LSH (Locality-Sensitive Hashing)** 的语义水印方案。

**核心思想**:
- 利用MoE模型的路由权重（Router Weights, RW）作为上下文相关的随机源
- 使用LSH将高维路由权重向量映射为二进制签名
- 基于LSH签名构建语义相关的绿色词汇池（Green List）
- 通过提升绿色词汇的logits来嵌入水印

### 1.2 水印嵌入机制

#### 1.2.1 路由权重提取

**代码位置**: `MoE_RW_Extractor.get_rw_vector()` (Lines 27-51)

**数学表示**:
设MoE模型有 $L$ 层，每层有 $E$ 个专家。对于第 $t$ 个token，提取的路由权重向量为：

$$\mathbf{rw}_t \in \mathbb{R}^{D}$$

其中 $D = (L_{end} - L_{start}) \times E$，表示从第 $L_{start}$ 层到第 $L_{end}$ 层的路由权重。

**提取过程**:
1. **层切片**: 选择特定范围的MoE层
   ```python
   sliced = sent_embs[:, start_layer:end_layer, :, :]
   ```

2. **Token选择**: 选择特定位置的token（通常是最后一个token）
   ```python
   selected = sliced[:, :, token_idx, :]  # Shape: (batch, layers, experts)
   ```

3. **Top-K过滤**（可选）: 只保留Top-K个专家的权重
   ```python
   if use_top_k:
       topk_weights, top_k_indices = torch.topk(selected, k, dim=-1)
       processed_rws.scatter_(dim=-1, index=top_k_indices, src=topk_weights)
   ```

4. **展平**: 将多维张量展平为一维向量
   ```python
   rw_vector = processed_rws.flatten(start_dim=1)  # Shape: (batch, D)
   ```

**数学意义**:
- 路由权重反映了模型对当前上下文的"专家选择偏好"
- 不同上下文会产生不同的路由权重分布
- 这种分布是**上下文相关的随机源**，比简单的哈希函数更难以预测

#### 1.2.2 LSH签名生成

**代码位置**: `LSH_Semantic_Encoder.get_signature()` (Lines 84-87)

**数学原理**:

LSH (Locality-Sensitive Hashing) 是一种将高维向量映射到低维二进制签名的技术。

**核心公式**:
$$\text{signature}_i = \text{sign}(\mathbf{r}_i \cdot \mathbf{rw}_t)$$

其中：
- $\mathbf{r}_i \in \mathbb{R}^{D}$ 是第 $i$ 个随机向量（LSH投影向量）
- $\mathbf{rw}_t$ 是路由权重向量
- $\text{sign}(x) = \begin{cases} 1 & \text{if } x > 0 \\ 0 & \text{if } x \leq 0 \end{cases}$

**实现**:
```python
dot_products = self.random_vectors.mv(rw_vector)  # 矩阵-向量乘法
signature = (dot_products > 0).int()  # 二值化
```

**数学性质**:
- **局部敏感性**: 相似的路由权重向量会产生相似的LSH签名
- **随机性**: 随机向量 $\mathbf{r}_i$ 确保签名的不可预测性
- **维度**: 签名长度为 `num_bits`（通常256位）

#### 1.2.3 语义词汇池构建

**代码位置**: `LSH_Semantic_Encoder._precompute_pools()` (Lines 67-82)

**核心创新**: 使用**语义相似度**而非随机选择来构建词汇池。

**数学过程**:

对于每个LSH位 $i$，构建一个语义词汇池 $P_i$：

1. **锚点选择**: 随机选择一个词汇作为锚点
   $$a_i \sim \text{Uniform}(0, V-1)$$

2. **语义相似度计算**: 计算所有词汇与锚点的余弦相似度
   $$\text{sim}_j = \cos(\mathbf{e}_{a_i}, \mathbf{e}_j) = \frac{\mathbf{e}_{a_i} \cdot \mathbf{e}_j}{||\mathbf{e}_{a_i}|| \cdot ||\mathbf{e}_j||}$$

   其中 $\mathbf{e}_j$ 是词汇 $j$ 的嵌入向量。

3. **Top-K选择**: 选择相似度最高的 $K$ 个词汇
   $$P_i = \text{TopK}(\{\text{sim}_j\}_{j=0}^{V-1}, K)$$

**优势**:
- **语义一致性**: 同一池中的词汇语义相似，替换时更自然
- **攻击鲁棒性**: 语义攻击（如同义词替换）难以破坏水印
- **质量保证**: 绿色词汇的选择更符合语言模型分布

#### 1.2.4 绿色名单生成

**代码位置**: `LSH_Semantic_Encoder.get_green_list()` (Lines 89-95)

**数学逻辑**:

给定LSH签名 $\mathbf{s} = [s_1, s_2, ..., s_B]$，绿色名单为：

$$\text{GreenList} = \bigcup_{i: s_i = 1} P_i$$

即：**所有签名位为1的词汇池的并集**。

**示例**:
- 假设 `num_bits = 4`, `pool_size = 10`
- 签名 = `[1, 0, 1, 0]`
- 绿色名单 = $P_0 \cup P_2$（两个池的并集，最多20个词汇）

**期望大小**:
$$\mathbb{E}[|\text{GreenList}|] = \frac{B}{2} \times K = \frac{\text{num_bits}}{2} \times \text{pool_size}$$

#### 1.2.5 Logits偏置

**代码位置**: `WatermarkGeneratorContext._watermarked_forward()` (Lines 123-130)

**数学操作**:

对于每个token位置，对绿色词汇的logits添加偏置：

$$\logits'[i, \text{green\_list}] = \logits[i, \text{green\_list}] + \delta$$

其中 $\delta > 0$ 是水印强度参数。

**概率影响**:

原始概率分布：
$$P(w_t | w_{<t}) = \frac{\exp(\logits[w_t])}{\sum_{v} \exp(\logits[v])}$$

水印后概率分布：
$$P'(w_t | w_{<t}) = \frac{\exp(\logits[w_t] + \delta \cdot \mathbf{1}[w_t \in \text{GreenList}])}{\sum_{v} \exp(\logits[v] + \delta \cdot \mathbf{1}[v \in \text{GreenList}])}$$

**效果**:
- 绿色词汇的概率提升：$P'(w) \propto P(w) \cdot \exp(\delta)$（如果 $w$ 在绿色名单中）
- 非绿色词汇的概率相对降低
- $\delta$ 越大，水印越强，但可能影响文本质量

### 1.3 水印检测机制

#### 1.3.1 增量检测流程

**代码位置**: `MoELSHWatermark.detect_watermark()` (Lines 205-256)

**算法流程**:

1. **Token化**: 将文本转换为token序列
   $$\mathbf{t} = [t_1, t_2, ..., t_N]$$

2. **逐Token检测**: 对于每个token $t_i$：
   - 提取路由权重：$\mathbf{rw}_i = \text{ExtractRW}(\mathbf{t}_{<i})$
   - 生成绿色名单：$\text{GreenList}_i = \text{GetGreenList}(\mathbf{rw}_i)$
   - 检查命中：$\text{hit}_i = \mathbf{1}[t_i \in \text{GreenList}_i]$

3. **统计计数**: 
   $$\text{hits} = \sum_{i=1}^{N} \text{hit}_i$$

#### 1.3.2 Z-Score计算

**代码位置**: Lines 244-250

**数学公式**:

$$z = \frac{\text{hits} - \mathbb{E}[\text{hits}]}{\sqrt{\text{Var}[\text{hits}]}}$$

其中：
- **期望值**: $\mathbb{E}[\text{hits}] = N \times p_{\text{green}}$
- **方差**: $\text{Var}[\text{hits}] = N \times p_{\text{green}} \times (1 - p_{\text{green}})$
- **绿色概率**: $p_{\text{green}} = \frac{\mathbb{E}[|\text{GreenList}|]}{V} = \frac{B \times K}{2V}$

**实现**:
```python
expected_fraction = avg_green_list_size / vocab_size
numerator = hits - expected_fraction * total_tokens
denominator = np.sqrt(total_tokens * expected_fraction * (1 - expected_fraction))
z_score = numerator / denominator
```

**统计意义**:
- **零假设**: 文本是随机生成的，绿色token比例 = $p_{\text{green}}$
- **备择假设**: 文本是水印生成的，绿色token比例 > $p_{\text{green}}$
- **Z-Score**: 衡量观察值与期望值的偏差（以标准差为单位）

**决策规则**:
$$\text{is\_watermarked} = \begin{cases}
\text{True} & \text{if } z > z_{\text{threshold}} \\
\text{False} & \text{otherwise}
\end{cases}$$

通常 $z_{\text{threshold}} = 2$ 或 $3$（对应95%或99.7%置信度）。

### 1.4 数学原理深度剖析

#### 1.4.1 LSH的局部敏感性

**定义**: 对于相似的路由权重向量 $\mathbf{rw}_1$ 和 $\mathbf{rw}_2$，它们的LSH签名应该相似。

**概率保证**:
$$P(\text{sign}(\mathbf{r}_i \cdot \mathbf{rw}_1) = \text{sign}(\mathbf{r}_i \cdot \mathbf{rw}_2)) = 1 - \frac{\theta}{\pi}$$

其中 $\theta$ 是两向量的夹角。

**意义**: 
- 上下文相似时，路由权重相似 → LSH签名相似 → 绿色名单重叠度高
- 这保证了**上下文一致性**：相同上下文总是产生相似的绿色名单

#### 1.4.2 绿色名单大小的分布

**理论分析**:

设LSH签名有 $B$ 位，每位的词汇池大小为 $K$。

**位为1的期望数量**: $\mathbb{E}[\text{bits} = 1] = \frac{B}{2}$（假设路由权重分布均匀）

**绿色名单大小的期望**:
$$\mathbb{E}[|\text{GreenList}|] = \sum_{i=1}^{B} P(\text{bit}_i = 1) \times K = \frac{B}{2} \times K$$

**方差**（考虑池之间的重叠）:
$$\text{Var}[|\text{GreenList}|] = \sum_{i,j} \text{Cov}(P_i, P_j)$$

由于池是独立构建的，重叠主要来自词汇本身的语义相似度。

#### 1.4.3 检测统计量的渐近分布

**中心极限定理**:

当 $N \to \infty$ 时，在零假设下：

$$\frac{\text{hits} - Np}{\sqrt{Np(1-p)}} \xrightarrow{d} \mathcal{N}(0, 1)$$

因此，Z-Score近似服从标准正态分布。

**检测概率**（Power）:

在水印假设下，绿色token的实际概率为 $p' > p$，则：

$$P(\text{检测到水印}) = P(Z > z_{\text{threshold}}) = 1 - \Phi\left(\frac{z_{\text{threshold}} - \frac{N(p'-p)}{\sqrt{Np(1-p)}}}{\sqrt{\frac{p'(1-p')}{p(1-p)}}}\right)$$

其中 $\Phi$ 是标准正态分布的CDF。

---

## 二、KGW 算法深度分析 {#kgw}

### 2.1 算法概述

**KGW (Kirchenbauer et al.)** 是第一个实用的生成式水印方案，使用**上下文相关的哈希函数**来生成绿色名单。

### 2.2 水印嵌入机制

#### 2.2.1 上下文函数 $f$

**代码位置**: `KGWUtils._f()` (Lines 66-90)

**数学定义**:

KGW使用多种上下文函数来生成随机种子：

1. **Time函数**:
   $$f_{\text{time}}(\mathbf{t}_{<i}) = \prod_{j=1}^{L} t_{i-j} \bmod V$$

2. **Additive函数**:
   $$f_{\text{additive}}(\mathbf{t}_{<i}) = \sum_{j=1}^{L} t_{i-j} \bmod V$$

3. **Skip函数**:
   $$f_{\text{skip}}(\mathbf{t}_{<i}) = t_{i-L}$$

4. **Min函数**:
   $$f_{\text{min}}(\mathbf{t}_{<i}) = \min_{j=1}^{L} \text{PRF}(t_{i-j})$$

其中 $L$ 是前缀长度（prefix_length），PRF是伪随机函数。

#### 2.2.2 绿色名单生成

**代码位置**: `KGWUtils._get_greenlist_ids_left()` (Lines 96-102)

**数学过程**:

1. **种子生成**:
   $$\text{seed} = (\text{hash\_key} \times f(\mathbf{t}_{<i})) \bmod V$$

2. **伪随机排列**:
   $$\text{permutation} = \text{PRF}(\text{seed}, V)$$

3. **绿色名单选择**:
   $$\text{GreenList}_i = \text{permutation}[:K]$$

其中 $K = \lfloor \gamma V \rfloor$，$\gamma$ 是绿色比例（通常0.5）。

**关键性质**:
- **确定性**: 相同上下文总是产生相同的绿色名单
- **随机性**: 不同上下文产生不同的绿色名单（看起来随机）
- **不可预测性**: 没有密钥无法预测绿色名单

#### 2.2.3 Logits偏置

与MoELSHWatermark相同，对绿色词汇添加偏置 $\delta$。

### 2.3 水印检测机制

#### 2.3.1 Z-Score计算

**代码位置**: `KGWUtils._compute_z_score()` (Lines 118-124)

**数学公式**:

$$z = \frac{C - \gamma N}{\sqrt{N \gamma (1-\gamma)}}$$

其中：
- $C$ 是观察到的绿色token数量
- $N$ 是总token数量
- $\gamma$ 是绿色比例

**统计意义**: 这是标准的**二项分布Z-Score**。

### 2.4 与MoELSHWatermark的对比

| 特性 | KGW | MoELSHWatermark |
|------|-----|-----------------|
| 随机源 | 上下文哈希 | MoE路由权重 |
| 绿色名单 | 随机选择 | 语义相似选择 |
| 上下文敏感性 | 基于token ID | 基于模型内部状态 |
| 攻击鲁棒性 | 中等 | 高（语义池） |

---

## 三、Unigram 算法深度分析 {#unigram}

### 3.1 算法概述

**Unigram** 是最简单的生成式水印方案，使用**固定的全局绿色名单**。

### 3.2 水印嵌入机制

#### 3.2.1 全局绿色名单

**代码位置**: `UnigramUtils.__init__()` (Lines 87-90)

**数学定义**:

$$\text{GreenList} = \{v : \text{mask}[v] = \text{True}\}$$

其中 `mask` 是一个固定的布尔向量，满足：

$$|\{v : \text{mask}[v] = \text{True}\}| = \lfloor \gamma V \rfloor$$

**生成方式**:
1. 创建初始mask：前 $\gamma V$ 个为True，其余为False
2. 使用密钥打乱：$\text{mask} = \text{Shuffle}(\text{mask}, \text{hash\_key})$

**关键特点**:
- **全局性**: 所有token位置使用相同的绿色名单
- **简单性**: 不需要上下文计算
- **效率**: 检测速度最快

### 3.3 水印检测机制

#### 3.3.1 Z-Score计算

与KGW完全相同：

$$z = \frac{C - \gamma N}{\sqrt{N \gamma (1-\gamma)}}$$

### 3.4 优缺点分析

**优点**:
- 实现简单
- 检测快速
- 计算开销小

**缺点**:
- 攻击鲁棒性差（固定绿色名单容易被识别）
- 无法利用上下文信息
- 可能影响文本质量（某些上下文下绿色词汇不合适）

---

## 四、EPW 算法深度分析 {#epw}

### 4.1 算法概述

**EPW (Expert-based Watermarking)** 是专门为MoE模型设计的水印方案，利用**Top-2专家**的路由信息。

### 4.2 水印嵌入机制

#### 4.2.1 Top-2专家选择

**代码位置**: `EPWUtils.get_top2_expert_info()` (Lines 122-154)

**数学过程**:

1. **路由logits**: 获取MoE层的路由logits
   $$\mathbf{rl}_t \in \mathbb{R}^{E}$$

2. **Softmax归一化**:
   $$\mathbf{p}_t = \text{softmax}(\mathbf{rl}_t)$$

3. **Top-2选择**:
   $$(e_1, e_2) = \text{Top2}(\mathbf{p}_t)$$
   $$(c_1, c_2) = (p_t[e_1], p_t[e_2])$$

其中 $e_1, e_2$ 是专家索引，$c_1, c_2$ 是置信度。

#### 4.2.2 加权绿色名单

**代码位置**: `OptimizedEPWLogitsProcessor.__call__()` (Lines 227-236)

**数学定义**:

对于Top-2专家 $(e_1, e_2)$，分别生成绿色名单：

$$\text{GreenList}_1 = \text{PRF}(\text{hash\_key}, e_1, \text{router\_hash})$$
$$\text{GreenList}_2 = \text{PRF}(\text{hash\_key}, e_2, \text{router\_hash})$$

**加权logits偏置**:

$$\logits'[w] = \logits[w] + \delta \times \left(\alpha_1 \cdot \mathbf{1}[w \in \text{GreenList}_1] + \alpha_2 \cdot \mathbf{1}[w \in \text{GreenList}_2]\right)$$

其中：
- $\alpha_1 = \frac{c_1}{c_1 + c_2}$（第一个专家的权重）
- $\alpha_2 = \frac{c_2}{c_1 + c_2}$（第二个专家的权重）

**优势**:
- **平滑性**: 使用加权而非硬选择，更自然
- **鲁棒性**: 即使专家选择略有变化，水印仍然有效

### 4.3 水印检测机制

#### 4.3.1 加权Z-Score计算

**代码位置**: `EPWUtils._calculate_weighted_z_score_precise()` (Lines 166-188)

**数学公式**:

$$z = \frac{S_{\text{observed}} - T\gamma}{\sqrt{T\gamma(1-\gamma)(\alpha_1^2 + \alpha_2^2)}}$$

其中：
- $S_{\text{observed}} = \sum_{t=1}^{T} s_t$（加权绿色token总和）
- $s_t = \alpha_1 \cdot \mathbf{1}[w_t \in \text{GreenList}_1] + \alpha_2 \cdot \mathbf{1}[w_t \in \text{GreenList}_2]$（第 $t$ 个token的权重）
- $\alpha_1^2 + \alpha_2^2$ 是权重平方和（考虑方差修正）

**方差修正**:

标准二项分布的方差是 $T\gamma(1-\gamma)$，但加权情况下需要修正：

$$\text{Var}[S] = T\gamma(1-\gamma)(\alpha_1^2 + \alpha_2^2)$$

**推导**（简化版）:

假设每个token独立，则：

$$\text{Var}[s_t] = \gamma(1-\gamma)(\alpha_1^2 + \alpha_2^2)$$

因此：

$$\text{Var}[S] = \sum_{t=1}^{T} \text{Var}[s_t] = T\gamma(1-\gamma)(\alpha_1^2 + \alpha_2^2)$$

### 4.4 与MoELSHWatermark的对比

| 特性 | EPW | MoELSHWatermark |
|------|-----|-----------------|
| 路由信息 | Top-2专家索引 | 完整路由权重向量 |
| 绿色名单 | 基于专家索引 | 基于LSH签名 |
| 语义性 | 无 | 有（语义池） |
| 加权方式 | 专家置信度 | 无（二值） |

---

## 五、算法对比与数学原理总结 {#comparison}

### 5.1 核心数学原理对比

| 算法 | 随机源 | 绿色名单生成 | Z-Score公式 |
|------|--------|-------------|-------------|
| **Unigram** | 固定mask | $\text{PRF}(\text{key})$ | $\frac{C-\gamma N}{\sqrt{N\gamma(1-\gamma)}}$ |
| **KGW** | $f(\text{context})$ | $\text{PRF}(\text{key} \times f)$ | $\frac{C-\gamma N}{\sqrt{N\gamma(1-\gamma)}}$ |
| **EPW** | Top-2专家 | $\text{PRF}(\text{key}, e_1, e_2)$ | $\frac{S-T\gamma}{\sqrt{T\gamma(1-\gamma)(\alpha_1^2+\alpha_2^2)}}$ |
| **MoELSH** | 路由权重 | LSH + 语义池 | $\frac{C-\gamma N}{\sqrt{N\gamma(1-\gamma)}}$ |

### 5.2 统计检测理论

#### 5.2.1 假设检验框架

**零假设 $H_0$**: 文本是随机生成的（无水印）
- 绿色token比例 = $\gamma$
- Z-Score ~ $\mathcal{N}(0, 1)$

**备择假设 $H_1$**: 文本是水印生成的
- 绿色token比例 > $\gamma$
- Z-Score > 0（显著正偏差）

#### 5.2.2 检测性能指标

**真阳性率 (TPR)**:
$$\text{TPR} = P(\text{检测到水印} | \text{有水印}) = 1 - \Phi(z_{\text{threshold}} - \mu)$$

其中 $\mu$ 是水印文本的Z-Score期望值。

**假阳性率 (FPR)**:
$$\text{FPR} = P(\text{检测到水印} | \text{无水印}) = 1 - \Phi(z_{\text{threshold}})$$

**ROC曲线**: 绘制TPR vs FPR，AUC越大越好。

#### 5.2.3 样本量要求

**最小样本量**（保证检测能力）:

对于给定的 $\alpha$（FPR）和 $\beta$（漏检率），最小样本量为：

$$N_{\min} = \frac{(z_{1-\alpha} + z_{1-\beta})^2 \gamma(1-\gamma)}{(\gamma' - \gamma)^2}$$

其中 $\gamma'$ 是水印文本的实际绿色比例。

### 5.3 攻击鲁棒性分析

#### 5.3.1 同义词替换攻击

**Unigram**: ❌ 脆弱（固定绿色名单）
**KGW**: ⚠️ 中等（上下文相关但无语义保护）
**EPW**: ⚠️ 中等（基于专家索引）
**MoELSH**: ✅ 鲁棒（语义池保证同义词在同一池中）

#### 5.3.2 重写攻击

**所有算法**: 重写会改变上下文，可能破坏水印
**MoELSH**: 相对更鲁棒（语义池提供一定保护）

#### 5.3.3 质量-鲁棒性权衡

**数学表示**:

$$\text{Quality} = f(\delta, \gamma)$$
$$\text{Robustness} = g(\delta, \gamma, \text{algorithm})$$

**优化问题**:
$$\max_{\delta, \gamma} \text{Robustness} \quad \text{s.t.} \quad \text{Quality} \geq \text{threshold}$$

### 5.4 实现优化技巧

#### 5.4.1 KV缓存优化

**MoELSHWatermark** 使用KV缓存加速检测：

```python
past_key_values = None
for token in tokens:
    rw_vector, past_key_values = extractor.get_rw_vector(token, past_key_values)
```

**复杂度**: 从 $O(N^2)$ 降低到 $O(N)$。

#### 5.4.2 批处理优化

**PPL计算** 使用批处理：

```python
for i in range(0, len(texts), batch_size):
    batch_texts = texts[i:i+batch_size]
    batch_ppls = model(batch_texts)
```

**加速比**: 约 $B$ 倍（$B$ 是batch size）。

---

## 六、数学证明与理论保证

### 6.1 LSH的局部敏感性证明

**定理**: 对于两个向量 $\mathbf{u}, \mathbf{v}$，它们的LSH签名相同的概率为：

$$P(\text{sign}(\mathbf{r} \cdot \mathbf{u}) = \text{sign}(\mathbf{r} \cdot \mathbf{v})) = 1 - \frac{\theta(\mathbf{u}, \mathbf{v})}{\pi}$$

**证明**（简化）:

设 $\mathbf{r}$ 是随机单位向量，则：

$$P(\text{sign}(\mathbf{r} \cdot \mathbf{u}) = \text{sign}(\mathbf{r} \cdot \mathbf{v})) = P((\mathbf{r} \cdot \mathbf{u})(\mathbf{r} \cdot \mathbf{v}) > 0)$$

通过几何分析，这个概率等于 $1 - \frac{\theta}{\pi}$。

### 6.2 Z-Score的渐近正态性

**定理**（中心极限定理）: 当 $N \to \infty$ 时，

$$\frac{\sum_{i=1}^{N} X_i - Np}{\sqrt{Np(1-p)}} \xrightarrow{d} \mathcal{N}(0, 1)$$

其中 $X_i \sim \text{Bernoulli}(p)$ 是独立的。

**应用**: 在零假设下，绿色token是独立的Bernoulli随机变量，因此Z-Score渐近正态。

### 6.3 检测能力的下界

**定理**: 对于给定的 $\alpha, \beta$，检测能力下界为：

$$\text{Power} \geq 1 - \Phi\left(\frac{z_{1-\alpha} - \frac{N(\gamma'-\gamma)}{\sqrt{N\gamma(1-\gamma)}}}{\sqrt{\frac{\gamma'(1-\gamma')}{\gamma(1-\gamma)}}}\right)$$

**意义**: 给出了检测能力的最小保证。

---

## 七、实践建议

### 7.1 参数选择

**$\gamma$ (绿色比例)**:
- 范围: $[0.3, 0.7]$
- 推荐: $0.5$（平衡检测能力和质量）

**$\delta$ (水印强度)**:
- 范围: $[0.5, 5.0]$
- 推荐: $[1.0, 2.0]$（根据质量要求调整）

**$z_{\text{threshold}}$ (检测阈值)**:
- 范围: $[2.0, 4.0]$
- 推荐: $2.0$（95%置信度）或 $3.0$（99.7%置信度）

### 7.2 算法选择指南

| 场景 | 推荐算法 | 理由 |
|------|---------|------|
| 简单快速 | Unigram | 实现简单，检测快 |
| 标准场景 | KGW | 平衡性能和质量 |
| MoE模型 | EPW/MoELSH | 利用MoE特性 |
| 高鲁棒性 | MoELSH | 语义池提供保护 |
| 低延迟 | Unigram | 无上下文计算 |

### 7.3 性能优化

1. **使用KV缓存**: 检测时复用计算结果
2. **批处理**: 同时处理多个样本
3. **预计算**: 预计算词汇池和LSH向量
4. **GPU加速**: 利用GPU并行计算

---

**文档版本**: v1.0  
**最后更新**: 2024  
**维护者**: 算法分析团队

